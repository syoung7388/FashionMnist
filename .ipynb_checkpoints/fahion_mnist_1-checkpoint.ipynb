{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a22c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataSet\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#import helper\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5,), (0.5,)) \n",
    "])\n",
    "\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download = True, train = True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 64, shuffle = True)\n",
    "\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download = True, train = False, transform = transform)\n",
    "testloader = torch.utils.data.DataLoader(trainset, batch_size = 64, shuffle = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19120a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test image\n",
    "\n",
    "def imgshow(image, ax = None, title = None, normalize = True ):\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    if normalize:\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image = std*image+mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "    ax.imshow(image)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.tick_params(axis = 'both', length = 0)\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_yticklabels('')\n",
    "    return ax\n",
    "image, label = next(iter(trainloader))\n",
    "\n",
    "imgshow(image[0, :]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86f5b8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the network \n",
    "\"\"\"\n",
    "input layer: 28*28 = 764\n",
    "hidden layer: 2개, 258, 128\n",
    "output layer: 10개 (구별할 옷이 열 종류)\n",
    "Adam Optimizer과 NLLLoss 활용\n",
    "\"\"\"\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.log_softmax(self.fc4(x), dim = 1)\n",
    "        return x\n",
    "\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e614be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5113844161253494\n",
      "Training loss: 0.3896492956194288\n",
      "Training loss: 0.35126941513691123\n"
     ]
    }
   ],
   "source": [
    "# train a model\n",
    "model = Classifier()\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.003)\n",
    "epochs = 20\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        #모델에서 훈련\n",
    "        result = model(images)\n",
    "        #오차 계산\n",
    "        loss = criterion(result, labels)\n",
    "        \n",
    "        #초기화\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #역전파\n",
    "        loss.backward()\n",
    "        \n",
    "        #스텝\n",
    "        optimizer.step()\n",
    "        \n",
    "        #오차값을 총 오차에 더함\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7f00b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "img = images[0]\n",
    "img = img.resize(1, 784)\n",
    "ps = torch.exp(model(img))\n",
    "helper.view_classify(img.resize_(1, 28, 28), ps, version = 'Fashion')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8296203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        log_ps = model(images)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        # Turn off gradients for validation, saves memory and computations\n",
    "        #자동 미분을 꺼서 pytorch가 쓸 떼 없는 짓을 안한다. \n",
    "        with torch.no_grad():\n",
    "            for images, labels in testloader:\n",
    "                \n",
    "                log_ps = model(images)\n",
    "                test_loss += criterion(log_ps, labels)\n",
    "                \n",
    "                #로그 확률에 지수 적용\n",
    "                ps = torch.exp(log_ps)\n",
    "                \n",
    "                #k번째로 큰 숫를 찾아낸다 / dim = 1 은 dimension을 의미한다.\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                \n",
    "                #labels를 top_class와 똑같은 형태로 만든 다음에, 얼마나 같은게 있는지 확인한다.\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                \n",
    "                #equals를 float으로 바꾸고 평균 정확도를 구한다.\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "        train_losses.append(running_loss/len(trainloader))\n",
    "        test_losses.append(test_loss/len(testloader))\n",
    "        \n",
    "        print(\n",
    "            \"Epoch:{}/{}..\".format(e+1, epochs),\n",
    "            \"Training Loss : {:.3f}..\".format(running_loss / len(trainloader)),\n",
    "            \"Test Loss: {:.3f}..\".format(test_loss/len(testloader))\n",
    "            \"Test Accuracy: {:3f}\".format(accuracy/len(testloader))\n",
    "             )\n",
    "        \n",
    "        \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe9c327",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label = \"training loss\")\n",
    "plt.plot(test_losses, label = \"Validation loss\")\n",
    "plt.legend(frameon = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
