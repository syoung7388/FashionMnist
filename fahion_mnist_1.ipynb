{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a22c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataSet\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#import helper\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5,), (0.5,)) \n",
    "])\n",
    "\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download = True, train = True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 64, shuffle = True)\n",
    "\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download = True, train = False, transform = transform)\n",
    "testloader = torch.utils.data.DataLoader(trainset, batch_size = 64, shuffle = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19120a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test image\n",
    "\n",
    "def imgshow(image, ax = None, title = None, normalize = True ):\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    if normalize:\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image = std*image+mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "    ax.imshow(image)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.tick_params(axis = 'both', length = 0)\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_yticklabels('')\n",
    "    return ax\n",
    "image, label = next(iter(trainloader))\n",
    "\n",
    "imgshow(image[0, :]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86f5b8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the network \n",
    "\"\"\"\n",
    "input layer: 28*28 = 764\n",
    "hidden layer: 2개, 258, 128\n",
    "output layer: 10개 (구별할 옷이 열 종류)\n",
    "Adam Optimizer과 NLLLoss 활용\n",
    "\"\"\"\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.log_softmax(self.fc4(x), dim = 1)\n",
    "        return x\n",
    "\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e614be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5139822473626401\n",
      "Training loss: 0.3898210830208081\n",
      "Training loss: 0.35880794113219927\n",
      "Training loss: 0.3360894813792093\n",
      "Training loss: 0.3151393597091693\n",
      "Training loss: 0.2997936102500094\n",
      "Training loss: 0.29500864615350136\n",
      "Training loss: 0.28162848785011246\n",
      "Training loss: 0.2722656931291257\n",
      "Training loss: 0.26774931157321563\n",
      "Training loss: 0.26400943457095355\n",
      "Training loss: 0.25919729755567844\n",
      "Training loss: 0.24675635132056944\n",
      "Training loss: 0.24238449023730718\n",
      "Training loss: 0.2376430097109537\n",
      "Training loss: 0.23119910304416727\n",
      "Training loss: 0.23178180963642944\n",
      "Training loss: 0.22580279145779006\n",
      "Training loss: 0.22018059043547333\n",
      "Training loss: 0.21534455945290354\n"
     ]
    }
   ],
   "source": [
    "# train a model\n",
    "model = Classifier()\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.003)\n",
    "epochs = 20\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        #모델에서 훈련\n",
    "        result = model(images)\n",
    "        #오차 계산\n",
    "        loss = criterion(result, labels)\n",
    "        \n",
    "        #초기화\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #역전파\n",
    "        loss.backward()\n",
    "        \n",
    "        #스텝\n",
    "        optimizer.step()\n",
    "        \n",
    "        #오차값을 총 오차에 더함\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad7f00b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndataiter = iter(testloader)\\nimages, labels = dataiter.next()\\nimg = images[0]\\nimg = img.resize(1, 784)\\nps = torch.exp(model(img))\\nhelper.view_classify(img.resize_(1, 28, 28), ps, version = 'Fashion')\\n\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "img = images[0]\n",
    "img = img.resize(1, 784)\n",
    "ps = torch.exp(model(img))\n",
    "helper.view_classify(img.resize_(1, 28, 28), ps, version = 'Fashion')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8296203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        log_ps = model(images)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        # Turn off gradients for validation, saves memory and computations\n",
    "        #자동 미분을 꺼서 pytorch가 쓸 떼 없는 짓을 안한다. \n",
    "        with torch.no_grad():\n",
    "            for images, labels in testloader:\n",
    "                \n",
    "                log_ps = model(images)\n",
    "                test_loss += criterion(log_ps, labels)\n",
    "                \n",
    "                #로그 확률에 지수 적용\n",
    "                ps = torch.exp(log_ps)\n",
    "                \n",
    "                #k번째로 큰 숫를 찾아낸다 / dim = 1 은 dimension을 의미한다.\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                \n",
    "                #labels를 top_class와 똑같은 형태로 만든 다음에, 얼마나 같은게 있는지 확인한다.\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                \n",
    "                #equals를 float으로 바꾸고 평균 정확도를 구한다.\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "        train_losses.append(running_loss/len(trainloader))\n",
    "        test_losses.append(test_loss/len(testloader))\n",
    "        \n",
    "        print(\n",
    "            \"Epoch:{}/{}..\".format(e+1, epochs),\n",
    "            \"Training Loss : {:.3f}..\".format(running_loss / len(trainloader)),\n",
    "            \"Test Loss: {:.3f}..\".format(test_loss/len(testloader))\n",
    "            \"Test Accuracy: {:3f}\".format(accuracy/len(testloader))\n",
    "             )\n",
    "        \n",
    "        \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe9c327",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label = \"training loss\")\n",
    "plt.plot(test_losses, label = \"Validation loss\")\n",
    "plt.legend(frameon = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
